{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfV2WAKJX8Bp",
    "outputId": "a83e6e87-e760-4d2b-d6dd-681b46b1895a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aY9STWi2f1K9",
    "outputId": "320e4579-e647-4517-aede-5e8a270f0eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxcetbMWf2Ga",
    "outputId": "31f8cf0d-5e3c-47e1-a4b7-e553d38024a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/M2/DeepLearning/deeplearningproject\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/M2/DeepLearning/deeplearningproject/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sU2-hBAFXhjZ"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from utils import get_init_embedding_feats\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import pos_tag, ne_chunk\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gULhX_mpXpkF",
    "outputId": "c77cc840-4aaa-49a8-c7fc-985253b278ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKSTuw63Xhja"
   },
   "source": [
    "### ENV Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30mF5YvKXhjb"
   },
   "source": [
    "- Download the glove if it does not exist. \r\n",
    "\r\n",
    "We used the Wikipedia 2014 + Gigaword 5 Glove (6B tokens, 400K vocab, uncased, 300d vectors). to initialize word embedding.\r\n",
    "\r\n",
    "https://nlp.stanford.edu/projects/glove/\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIn3oYBiXhjc",
    "outputId": "5082d4f5-4fe2-4294-98f7-1796531ad810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import wget\n",
    "from os import path\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "glove_dir = \"glove\"\n",
    "glove_url = \"https://nlp.stanford.edu/data/wordvecs/glove.6B.300d.zip\"\n",
    "\n",
    "\n",
    "# Download glove vector if not exit\n",
    "if not path.exists(\"glove\"):\n",
    "    if not os.path.exists(glove_dir):\n",
    "        os.mkdir(glove_dir)\n",
    "    wget.download(glove_url, out=glove_dir)\n",
    "    # Extract glove file\n",
    "    with zipfile.ZipFile(os.path.join(\"glove\", \"glove.6B.300d.zip\"), \"r\") as z:\n",
    "        z.extractall(glove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFk7LkooXhjc"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yy46NL2nI-K"
   },
   "source": [
    "**Architecture** : Encoder-decoder RNN with attention. (Feature-rich encoder).\r\n",
    "* Encoder : Bidirectionnel GRU-RNN. \r\n",
    "* Decoder : Unidirectionnel GRU-RNN with the same hidden-state size as the encoder. \r\n",
    "* Attention : Bahdanau attention mechanism.\r\n",
    "* Softmax layer over the target vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtRdMLfVqjHx"
   },
   "source": [
    "**Feature-rich encoder** :\r\n",
    "Capturing additional linguistic features, such as part-of-speech tags (**POS**), named-entity (**NER**) tags, and TF-IDF statics of the words.\r\n",
    "\r\n",
    "All of this features and the word based embeddings are passed as an input to the encoder after a concatenation into one long vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RhXBQXuXhjd"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "class Model(object):\n",
    "    def __init__(self, reversed_dict, article_max_len, summary_max_len, args, forward_only=False):\n",
    "        self.vocabulary_size = len(reversed_dict)\n",
    "        self.embedding_size = args.embedding_size\n",
    "        self.num_hidden = args.num_hidden\n",
    "        self.num_layers = args.num_layers\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.beam_width = args.beam_width\n",
    "        if not forward_only:\n",
    "            self.keep_prob = args.keep_prob\n",
    "        else:\n",
    "            self.keep_prob = 1.0\n",
    "        self.cell = tf.nn.rnn_cell.BasicLSTMCell\n",
    "        with tf.variable_scope(\"decoder/projection\"):\n",
    "            self.projection_layer = tf.layers.Dense(self.vocabulary_size, use_bias=False)\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32, (), name=\"batch_size\")\n",
    "        self.X = tf.placeholder(tf.int32, [None, article_max_len])\n",
    "        self.X_len = tf.placeholder(tf.int32, [None])\n",
    "        self.decoder_input = tf.placeholder(tf.int32, [None, summary_max_len])\n",
    "        self.decoder_len = tf.placeholder(tf.int32, [None])\n",
    "        self.decoder_target = tf.placeholder(tf.int32, [None, summary_max_len])\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            if not forward_only and args.glove:\n",
    "                \n",
    "                init_embeddings = tf.constant(get_init_embedding_feats(reversed_dict, self.embedding_size), dtype=tf.float32)\n",
    "            else:\n",
    "                init_embeddings = tf.random_uniform([self.vocabulary_size, self.embedding_size], -1.0, 1.0)\n",
    "            self.embeddings = tf.get_variable(\"embeddings\", initializer=init_embeddings)\n",
    "            self.encoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.X), perm=[1, 0, 2])\n",
    "            self.decoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.decoder_input), perm=[1, 0, 2])\n",
    "\n",
    "        with tf.name_scope(\"encoder\"):\n",
    "            fw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n",
    "            bw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n",
    "            fw_cells = [rnn.DropoutWrapper(cell) for cell in fw_cells]\n",
    "            bw_cells = [rnn.DropoutWrapper(cell) for cell in bw_cells]\n",
    "\n",
    "            encoder_outputs, encoder_state_fw, encoder_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "                fw_cells, bw_cells, self.encoder_emb_inp,\n",
    "                sequence_length=self.X_len, time_major=True, dtype=tf.float32)\n",
    "            self.encoder_output = tf.concat(encoder_outputs, 2)\n",
    "            encoder_state_c = tf.concat((encoder_state_fw[0].c, encoder_state_bw[0].c), 1)\n",
    "            encoder_state_h = tf.concat((encoder_state_fw[0].h, encoder_state_bw[0].h), 1)\n",
    "            self.encoder_state = rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "        with tf.name_scope(\"decoder\"), tf.variable_scope(\"decoder\") as decoder_scope:\n",
    "            decoder_cell = self.cell(self.num_hidden * 2)\n",
    "\n",
    "            if not forward_only:\n",
    "                attention_states = tf.transpose(self.encoder_output, [1, 0, 2])\n",
    "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                    self.num_hidden * 2, attention_states, memory_sequence_length=self.X_len, normalize=True)\n",
    "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
    "                                                                   attention_layer_size=self.num_hidden * 2)\n",
    "                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
    "                initial_state = initial_state.clone(cell_state=self.encoder_state)\n",
    "                helper = tf.contrib.seq2seq.TrainingHelper(self.decoder_emb_inp, self.decoder_len, time_major=True)\n",
    "                decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, initial_state)\n",
    "                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True, scope=decoder_scope)\n",
    "                self.decoder_output = outputs.rnn_output\n",
    "                self.logits = tf.transpose(\n",
    "                    self.projection_layer(self.decoder_output), perm=[1, 0, 2])\n",
    "                self.logits_reshape = tf.concat(\n",
    "                    [self.logits, tf.zeros([self.batch_size, summary_max_len - tf.shape(self.logits)[1], self.vocabulary_size])], axis=1)\n",
    "            else:\n",
    "                tiled_encoder_output = tf.contrib.seq2seq.tile_batch(\n",
    "                    tf.transpose(self.encoder_output, perm=[1, 0, 2]), multiplier=self.beam_width)\n",
    "                tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(self.encoder_state, multiplier=self.beam_width)\n",
    "                tiled_seq_len = tf.contrib.seq2seq.tile_batch(self.X_len, multiplier=self.beam_width)\n",
    "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                    self.num_hidden * 2, tiled_encoder_output, memory_sequence_length=tiled_seq_len, normalize=True)\n",
    "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
    "                                                                   attention_layer_size=self.num_hidden * 2)\n",
    "                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size * self.beam_width)\n",
    "                initial_state = initial_state.clone(cell_state=tiled_encoder_final_state)\n",
    "                decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                    cell=decoder_cell,\n",
    "                    embedding=self.embeddings,\n",
    "                    start_tokens=tf.fill([self.batch_size], tf.constant(2)),\n",
    "                    end_token=tf.constant(3),\n",
    "                    initial_state=initial_state,\n",
    "                    beam_width=self.beam_width,\n",
    "                    output_layer=self.projection_layer\n",
    "                )\n",
    "                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder, output_time_major=True, maximum_iterations=summary_max_len, scope=decoder_scope)\n",
    "                self.prediction = tf.transpose(outputs.predicted_ids, perm=[1, 2, 0])\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            if not forward_only:\n",
    "                crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    logits=self.logits_reshape, labels=self.decoder_target)\n",
    "                weights = tf.sequence_mask(self.decoder_len, summary_max_len, dtype=tf.float32)\n",
    "                self.loss = tf.reduce_sum(crossent * weights / tf.to_float(self.batch_size))\n",
    "\n",
    "                params = tf.trainable_variables()\n",
    "                gradients = tf.gradients(self.loss, params)\n",
    "                clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "                optimizer = tf.train.AdadeltaOptimizer(self.learning_rate)\n",
    "                self.update = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUxYn3lkXhjk"
   },
   "source": [
    "### Training\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFJbCventeAj"
   },
   "source": [
    "Here we tried to reproduce the training phase of the paper.\r\n",
    "* Encoder-decoder hidden-state size : 400\r\n",
    "* Optimizer : Adadelta.\r\n",
    "* Learning rate : 0.001.\r\n",
    "* batch-size : 50.\r\n",
    "* Gradient clipping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVM8WAXIyW-z"
   },
   "source": [
    "For lack of time and performance reasons, we used a reduced dataset to train and test the model.\r\n",
    "\r\n",
    "**Train** : 10,000 pairs of article, summary.\r\n",
    "\r\n",
    "**Test**  : 1000 pairs of article, summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYdESWI7Xhjo",
    "outputId": "b6d54275-60bb-4521-832c-3f273d441470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary...\n",
      "Loading training dataset...\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:19: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:20: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:22: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:34: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:35: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:40: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:101: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:103: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/M2/DeepLearning/deeplearningproject/model.py:106: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "\n",
      "Iteration starts.\n",
      "Number of batches per epoch : 157\n",
      " Epoch 1: Model is saved. Elapsed: 00:04:32.75 \n",
      "\n",
      " Epoch 2: Model is saved. Elapsed: 00:08:55.12 \n",
      "\n",
      " Epoch 3: Model is saved. Elapsed: 00:13:15.40 \n",
      "\n",
      " Epoch 4: Model is saved. Elapsed: 00:17:35.62 \n",
      "\n",
      " Epoch 5: Model is saved. Elapsed: 00:21:55.26 \n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      " Epoch 6: Model is saved. Elapsed: 00:26:15.57 \n",
      "\n",
      "step 1000: loss = 27.23576545715332\n",
      " Epoch 7: Model is saved. Elapsed: 00:30:37.42 \n",
      "\n",
      " Epoch 8: Model is saved. Elapsed: 00:34:58.40 \n",
      "\n",
      " Epoch 9: Model is saved. Elapsed: 00:39:19.48 \n",
      "\n",
      " Epoch 10: Model is saved. Elapsed: 00:43:41.19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "from model import Model\n",
    "from utils import build_dict, build_dataset, batch_iter\n",
    "\n",
    "params = {\n",
    "    \"batch_size\":50, \n",
    "    \"beam_width\":10, \n",
    "    \"embedding_size\":300, \n",
    "    \"glove\":False, \n",
    "    \"keep_prob\":0.8, \n",
    "    \"learning_rate\":0.001, \n",
    "    \"num_epochs\":10, \n",
    "    \"num_hidden\":400, \n",
    "    \"num_layers\":2,\n",
    "    \"toy\":False, \n",
    "    \"with_model\":False\n",
    "}\n",
    "class Arg(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "args = Arg(params)\n",
    "\n",
    "if not os.path.exists(\"saved_model\"):\n",
    "    os.mkdir(\"saved_model\")\n",
    "else:\n",
    "    if args['with_model']:\n",
    "        old_model_checkpoint_path = open('saved_model/checkpoint', 'r')\n",
    "        old_model_checkpoint_path = \"\".join([\"saved_model/\",old_model_checkpoint_path.read().splitlines()[0].split('\"')[1] ])\n",
    "\n",
    "\n",
    "print(\"Building dictionary...\")\n",
    "word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"train\", args.toy)\n",
    "print(\"Loading training dataset...\")\n",
    "train_x, train_y = build_dataset(\"train\", word_dict, article_max_len, summary_max_len, args.toy)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = Model(reversed_dict, article_max_len, summary_max_len, args)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    if 'old_model_checkpoint_path' in globals():\n",
    "        print(\"Continuing from previous trained model:\" , old_model_checkpoint_path , \"...\")\n",
    "        saver.restore(sess, old_model_checkpoint_path )\n",
    "\n",
    "    batches = batch_iter(train_x, train_y, args.batch_size, args.num_epochs)\n",
    "    num_batches_per_epoch = (len(train_x) - 1) // args.batch_size + 1\n",
    "\n",
    "    print(\"\\nIteration starts.\")\n",
    "    print(\"Number of batches per epoch :\", num_batches_per_epoch)\n",
    "    for batch_x, batch_y in batches:\n",
    "        batch_x_len = list(map(lambda x: len([y for y in x if y != 0]), batch_x))\n",
    "        batch_decoder_input = list(map(lambda x: [word_dict[\"<s>\"]] + list(x), batch_y))\n",
    "        batch_decoder_len = list(map(lambda x: len([y for y in x if y != 0]), batch_decoder_input))\n",
    "        batch_decoder_output = list(map(lambda x: list(x) + [word_dict[\"</s>\"]], batch_y))\n",
    "\n",
    "        batch_decoder_input = list(\n",
    "            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_input))\n",
    "        batch_decoder_output = list(\n",
    "            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_output))\n",
    "\n",
    "        train_feed_dict = {\n",
    "            model.batch_size: len(batch_x),\n",
    "            model.X: batch_x,\n",
    "            model.X_len: batch_x_len,\n",
    "            model.decoder_input: batch_decoder_input,\n",
    "            model.decoder_len: batch_decoder_len,\n",
    "            model.decoder_target: batch_decoder_output\n",
    "        }\n",
    "\n",
    "        _, step, loss = sess.run([model.update, model.global_step, model.loss], feed_dict=train_feed_dict)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(\"step {0}: loss = {1}\".format(step, loss))\n",
    "\n",
    "        if step % num_batches_per_epoch == 0:\n",
    "            hours, rem = divmod(time.perf_counter() - start, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            saver.save(sess, \"./saved_model/model.ckpt\", global_step=step)\n",
    "            print(\" Epoch {0}: Model is saved.\".format(step // num_batches_per_epoch),\n",
    "            \"Elapsed: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds) , \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKcQBM8PXhjq"
   },
   "source": [
    "### Test\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fGxU31MXhjr",
    "outputId": "ef1eca4a-55a7-4bbb-e8f7-2e84a361628d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary...\n",
      "Loading validation dataset...\n",
      "Loading saved model...\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/seq2seq/python/ops/beam_search_decoder.py:971: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt-1570\n",
      "Writing summaries to 'result.txt'...\n",
      "Summaries are saved to \"result.txt\"...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from utils import build_dict, build_dataset, batch_iter\n",
    "\n",
    "\n",
    "with open(\"args.pickle\", \"rb\") as f:\n",
    "    args = pickle.load(f)\n",
    "\n",
    "print(\"Loading dictionary...\")\n",
    "word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"valid\", args.toy)\n",
    "print(\"Loading validation dataset...\")\n",
    "valid_x = build_dataset(\"valid\", word_dict, article_max_len, summary_max_len, args.toy)\n",
    "valid_x_len = [len([y for y in x if y != 0]) for x in valid_x]\n",
    "len(valid_x)\n",
    "with tf.Session() as sess:\n",
    "    print(\"Loading saved model...\")\n",
    "    model = Model(reversed_dict, article_max_len, summary_max_len, args, forward_only=True)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(\"./saved_model/\")\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    batches = batch_iter(valid_x, [0] * len(valid_x), args.batch_size, 1)\n",
    "\n",
    "    print(\"Writing summaries to 'result.txt'...\")\n",
    "    for batch_x, _ in batches:\n",
    "        batch_x_len = [len([y for y in x if y != 0]) for x in batch_x]\n",
    "\n",
    "        valid_feed_dict = {\n",
    "            model.batch_size: len(batch_x),\n",
    "            model.X: batch_x,\n",
    "            model.X_len: batch_x_len,\n",
    "        }\n",
    "\n",
    "        prediction = sess.run(model.prediction, feed_dict=valid_feed_dict)\n",
    "        prediction_output = [[reversed_dict[y] for y in x] for x in prediction[:, 0, :]]\n",
    "        summaries = []\n",
    "        open(filename, 'w').close()\n",
    "        with open(\"result.txt\", \"a\") as f:\n",
    "            for line in prediction_output:\n",
    "                summary = list()\n",
    "                for word in line:\n",
    "                    if word == \"</s>\":\n",
    "                        break\n",
    "                    if word not in summary:\n",
    "                        summary.append(word)\n",
    "                s = \" \".join(summary)\n",
    "                summaries.append(s)\n",
    "                print(s, file=f)\n",
    "\n",
    "    print('Summaries are saved to \"result.txt\"...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPvl6GTP4Z1E"
   },
   "source": [
    "####Evaluation\r\n",
    "\r\n",
    "For evaluation we used ROUGE-1, ROUGE-2, and ROUGE-L. \r\n",
    "\r\n",
    "Average ROUGE score (R)recall, (P)precision, or F1-score on all summaries is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlR0lFM-lXsK"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFhsibBJjHeW"
   },
   "outputs": [],
   "source": [
    "summaries_hat = []  \r\n",
    "with open(\"result.txt\", \"r\") as f:\r\n",
    "    for line in f:\r\n",
    "        summaries_hat.append(line[:-1])\r\n",
    "\r\n",
    "summaries = []  \r\n",
    "with open(\"reduceddata/sumdata/train/valid.title.filter.txt\", \"r\") as f:\r\n",
    "    for line in f:\r\n",
    "        summaries.append(line)\r\n",
    "articles = []  \r\n",
    "with open(\"reduceddata/sumdata/train/valid.article.filter.txt\", \"r\") as f:\r\n",
    "    for line in f:\r\n",
    "        articles.append(line)\r\n",
    "\r\n",
    "\r\n",
    "def printRandomExamples(articles, y, y_hat, n_examples = 3):\r\n",
    "    for i in range(n_examples):\r\n",
    "        j = np.random.randint(0, len(articles))\r\n",
    "        print(\"-\"*10)\r\n",
    "        print(f'Article {i+1} :')\r\n",
    "        print(articles[j])\r\n",
    "        print('Original summary :')\r\n",
    "        print(y[j])\r\n",
    "        print('Generated summary :')\r\n",
    "        print(y_hat[j])\r\n",
    "        print('\\n')\r\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80uf-BSGjYc7",
    "outputId": "2a9cf9ae-a0d8-43aa-a2f8-5322988dc9c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1 -----------------\n",
      "germany 's martina glagow won the women 's world cup biathlon ##.# km line start race here on sunday ahead of russia 's olga pyleva and katrin <unk> of germany .\n",
      "\n",
      "Original summary -----------------\n",
      "glagow wins women 's world cup biathlon ##.# km\n",
      "\n",
      "Generated summary -----------------\n",
      "< unk > wins win\n",
      "\n",
      "\n",
      "Article 2 -----------------\n",
      "fallen australian tennis star mark philippoussis on saturday was given wildcard entry into the main draw of this month 's australian open .\n",
      "\n",
      "Original summary -----------------\n",
      "australian men 's hardcourt tennis results\n",
      "\n",
      "Generated summary -----------------\n",
      "rees dow super-middleweight crown\n",
      "\n",
      "\n",
      "Article 3 -----------------\n",
      "a swiss court on monday refused to hand over documents requested by russia regarding oil giant yukos , overturning a previous legal ruling .\n",
      "\n",
      "Original summary -----------------\n",
      "swiss court refuses to transmit yukos documents to russia\n",
      "\n",
      "Generated summary -----------------\n",
      "frenchman calls for human rights group\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printRandomExamples(articles, summaries, summaries_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux9xycxu36DF"
   },
   "source": [
    "https://pypi.org/project/py-rouge/\r\n",
    "* The folder \"rouge\" of this package should be placed in the root of the project directory\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhHexz_FvTzq"
   },
   "outputs": [],
   "source": [
    "import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_683cKDeywmA"
   },
   "outputs": [],
   "source": [
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l'],\r\n",
    "                        max_n = 2,\r\n",
    "                        limit_length=True,\r\n",
    "                        length_limit=15,\r\n",
    "                        length_limit_type='words',\r\n",
    "                        apply_avg=True,\r\n",
    "                        stemming=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPii8oa40Mwi"
   },
   "outputs": [],
   "source": [
    "scores = evaluator.get_scores(summaries_hat, summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0xoDoPS2GBM"
   },
   "outputs": [],
   "source": [
    "def prepare_results(p, r, f):\r\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j795OFLG1hoU",
    "outputId": "8618b511-ef00-4a73-de71-f08d0e447bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 14.87\tR:  9.92\tF1: 11.50\n",
      "\trouge-2:\tP:  3.36\tR:  2.40\tF1:  2.71\n",
      "\trouge-l:\tP: 14.68\tR:  9.77\tF1: 11.33\n"
     ]
    }
   ],
   "source": [
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\r\n",
    "     print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_summarization_feats.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
